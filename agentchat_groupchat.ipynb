{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Group Chat\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "This notebook is modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install \"pyautogen>=0.2.3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ.setdefault(\"OAI_CONFIG_LIST\", json.dumps([\n",
    "    {\n",
    "        \"model\": \"gpt-4-1106-preview\",\n",
    "        \"api_key\": \"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\"\n",
    "    }\n",
    "]))\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-1106-preview\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# config_list_gpt35 = autogen.config_list_from_json(\n",
    "#     \"OAI_CONFIG_LIST\",\n",
    "#     filter_dict={\n",
    "#         \"model\": {\n",
    "#             \"gpt-3.5-turbo\",\n",
    "#             \"gpt-3.5-turbo-16k\",\n",
    "#             \"gpt-3.5-turbo-0301\",\n",
    "#             \"chatgpt-35-turbo-0301\",\n",
    "#             \"gpt-35-turbo-v0301\",\n",
    "#         },\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list_gpt4, \"cache_seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 2,\n",
    "        \"work_dir\": \"groupchat\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=50)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "To find the latest paper about GPT-4 on arXiv, I will provide you with a Python script that queries the arXiv API for papers related to \"gpt-4\". The script will search for the most recent papers and output the title, authors, summary, and URL of the latest paper. Once we have this information, we can analyze the summary to find potential applications in software.\n",
      "\n",
      "Here is a Python code to query the arXiv API:\n",
      "\n",
      "```python\n",
      "# filename: arxiv_gpt4_search.py\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import feedparser\n",
      "\n",
      "# Base api query url\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search parameters\n",
      "query = 'gpt-4'\n",
      "max_results = 1\n",
      "sort_by = 'submittedDate'\n",
      "sort_order = 'descending'\n",
      "\n",
      "# Construct query with parameters\n",
      "query_params = urllib.parse.urlencode({\n",
      "    \"search_query\": query,\n",
      "    \"start\": 0,\n",
      "    \"max_results\": max_results,\n",
      "    \"sortBy\": sort_by,\n",
      "    \"sortOrder\": sort_order\n",
      "})\n",
      "\n",
      "# Perform the GET request\n",
      "response = urllib.request.urlopen(base_url + query_params).read()\n",
      "\n",
      "# Parse the response using feedparser\n",
      "feed = feedparser.parse(response)\n",
      "\n",
      "if len(feed.entries) > 0:\n",
      "    entry = feed.entries[0]\n",
      "    print(\"Title: \", entry.title)\n",
      "    print(\"Authors: \", ', '.join(author.name for author in entry.authors))\n",
      "    print(\"Abstract: \", entry.summary)\n",
      "    print(\"URL: \", entry.link)\n",
      "else:\n",
      "    print(\"No papers found on GPT-4.\")\n",
      "```\n",
      "\n",
      "Please execute this script, and then provide me with the output. The potential applications in software will be deduced based on the paper's summary if available.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"arxiv_gpt4_search.py\", line 4, in <module>\n",
      "    import feedparser\n",
      "ModuleNotFoundError: No module named 'feedparser'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"arxiv_gpt4_search.py\", line 4, in <module>\n",
      "    import feedparser\n",
      "ModuleNotFoundError: No module named 'feedparser'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there was a missing module 'feedparser' which is required to parse the response from arXiv API. We can refine our python script to avoid using `feedparser` by processing the response with `xml.etree.ElementTree`, which is included in the Python standard library.\n",
      "\n",
      "I will adjust the script to make use of `xml.etree.ElementTree` for parsing the XML response:\n",
      "\n",
      "```python\n",
      "# filename: arxiv_gpt4_search.py\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "# Base api query url\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search parameters\n",
      "query = 'gpt-4'\n",
      "max_results = 1\n",
      "sort_by = 'submittedDate'\n",
      "sort_order = 'descending'\n",
      "\n",
      "# Construct query with parameters\n",
      "query_params = urllib.parse.urlencode({\n",
      "    \"search_query\": query,\n",
      "    \"start\": 0,\n",
      "    \"max_results\": max_results,\n",
      "    \"sortBy\": sort_by,\n",
      "    \"sortOrder\": sort_order\n",
      "})\n",
      "\n",
      "# Perform the GET request\n",
      "response = urllib.request.urlopen(base_url + query_params).read()\n",
      "\n",
      "# Parse the response using ElementTree\n",
      "root = ET.fromstring(response)\n",
      "\n",
      "# arXiv namespace\n",
      "ns = {'arxiv': 'http://arxiv.org/schemas/atom'}\n",
      "\n",
      "# Find the entry element in the feed\n",
      "entry = root.find('arxiv:entry', ns)\n",
      "\n",
      "if entry is not None:\n",
      "    # Extract and output necessary information from the entry\n",
      "    title = entry.find('arxiv:title', ns).text\n",
      "    authors = [author.find('arxiv:name', ns).text for author in entry.findall('arxiv:author', ns)]\n",
      "    summary = entry.find('arxiv:summary', ns).text\n",
      "    url = entry.find('arxiv:id', ns).text\n",
      "\n",
      "    print(\"Title: \", title)\n",
      "    print(\"Authors: \", ', '.join(authors))\n",
      "    print(\"Abstract: \", summary)\n",
      "    print(\"URL: \", url)\n",
      "else:\n",
      "    print(\"No papers found on GPT-4.\")\n",
      "```\n",
      "\n",
      "Please execute the updated script. This should resolve the issue and give us the details of the latest paper about GPT-4 on arXiv. Once you provide the output, I can analyze the summary for potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "No papers found on GPT-4.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "The script did not find any papers specifically on GPT-4 on arXiv, which could mean that no papers have been published with \"GPT-4\" explicitly in the title or abstract recently. Since I can't generate real-time data or access databases directly to verify this, you might need to manually search arXiv or other academic databases, or keep an eye on news from the organizations developing such models for any updates on research publications.\n",
      "\n",
      "However, let's consider potential applications based on the known capabilities of generative pre-trained transformers like GPT-3, which GPT-4 would presumably improve upon:\n",
      "\n",
      "1. **Natural Language Understanding and Generation**: GPT-4 could be employed to create more advanced chatbots and virtual assistants with better conversational abilities, understanding context, and maintaining coherence over long dialogues.\n",
      "\n",
      "2. **Content Creation**: It could assist in generating articles, reports, code, poetry, and other written content with more depth, creativity, and accuracy.\n",
      "\n",
      "3. **Language Translation**: GPT-4 might offer more accurate and nuanced language translation services, catching subtleties and idioms that previous models might miss.\n",
      "\n",
      "4. **Education**: It could be used to personalize learning materials and feedback for students by dynamically adjusting to a student's level of understanding and learning style.\n",
      "\n",
      "5. **Programming Assistant**: Enhanced programming assistants like GitHub Copilot could be built using GPT-4, providing even more accurate code suggestions and helping with bug fixes.\n",
      "\n",
      "6. **Data Analysis**: Integrating GPT-4 with data analytics software to automatically generate insights, create reports, and visualize data could be another application.\n",
      "\n",
      "7. **Gaming**: Improving non-player character (NPC) interactions in video games, creating dynamic storylines, and procedural content generation.\n",
      "\n",
      "8. **Research**: Assisting researchers in summarizing literature, generating hypothesis, and even writing research papers.\n",
      "\n",
      "9. **Legal and Compliance**: Automated analysis of legal documents and compliance monitoring, reducing the manual workload on legal professionals.\n",
      "\n",
      "10. **Healthcare**: Assisting in generating medical reports, providing preliminary diagnostic suggestions, and personalizing patient care through interactive systems.\n",
      "\n",
      "It is important to note that as AI models become more capable, ethical considerations and guidelines for responsible usage become critical to ensure these applications benefit society and do not cause harm.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems you're finished with the current discussion regarding GPT-4 and its potential applications. If you have any other questions, need further assistance, or if there are other topics you'd like to explore, feel free to ask. Whether it's more information about AI, technology trends, or any other subjects of interest, I'm here to help!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "Alright, if you have any further questions in the future or need assistance on any topic, don't hesitate to reach out. Have a great day!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "Hello! It seems there might be an issue since you haven't provided any new input. If you have any questions or need assistance with a certain topic, please let me know. I'm here to help!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\"\n",
    ")\n",
    "# type exit to terminate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
